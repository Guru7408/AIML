{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5621c648-863b-4e2e-ba36-9bc4cd66abf0",
   "metadata": {},
   "source": [
    "# Experiment-13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7be7e2-d0dd-430f-bf52-97549b349852",
   "metadata": {},
   "source": [
    "# 13) Write a NLP program to demonstrat following tasks\n",
    "### a)Tokenization, Removal of Stopword, Removal of punctuations,POS and NER Tagging\n",
    "### b)to demonstrate Bag of words,TF & IDF Vectrization, N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb71aa-f13e-4dc6-bd0c-a7546de33baa",
   "metadata": {},
   "source": [
    "### a)Tokenization, Removal of Stopword, Removal of punctuations,POS and NER Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc9607-f04f-440a-a2c9-20f09b85aba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39841843-7f55-4da8-9cdb-711adeff81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag, ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54b52baf-7ac2-45c1-9338-d1061275a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d4bba49-0599-46c8-ae4c-d66e0236cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple is looking at buying U.K. startup for $1 billion in 2025.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e68ea6e3-c51e-4bc3-9213-5a05cb7651d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Apple', 'is', 'looking', 'at', 'buying', 'U.K.', 'startup', 'for', '$', '1', 'billion', 'in', '2025', '.']\n"
     ]
    }
   ],
   "source": [
    "#Tokenization → Breaking text into words\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3f0909a-8b9c-4b8f-bf73-704602aac1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stopword Removal: ['Apple', 'looking', 'buying', 'startup', 'billion']\n"
     ]
    }
   ],
   "source": [
    "#Stopword Removal → Filtering out common words\n",
    "# Stopword Removal\n",
    "filtered = [w for w in tokens if w.isalpha() and w.lower() not in stopwords.words(\"english\")]\n",
    "print(\"After Stopword Removal:\", filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f978a93b-11ec-4757-813c-e49ea4d1a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Punctuation Removal: ['Apple', 'looking', 'buying', 'startup', 'billion']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Remove punctuation (just in case any remain)\n",
    "tokens_no_punct = [w for w in filtered if w not in string.punctuation]\n",
    "\n",
    "print(\"After Punctuation Removal:\", tokens_no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e158f4ef-cab5-447d-9f07-56dffa2a2207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('Apple', 'NNP'), ('looking', 'VBG'), ('buying', 'VBG'), ('startup', 'NN'), ('billion', 'CD')]\n"
     ]
    }
   ],
   "source": [
    "#POS Tagging → Identifying word roles (noun, verb, etc.)\n",
    "# POS Tagging(Part of Speech)\n",
    "print(\"POS Tags:\", pos_tag(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc704aef-64eb-44da-9a54-ef960b732511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER: [('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY'), ('2025', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "#NER → Extracting entities like names, dates, money\n",
    "# Named Entity Recognition\n",
    "doc = nlp(text)\n",
    "print(\"NER:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9993d74a-e39c-4740-a6f8-7df5aa0998b8",
   "metadata": {},
   "source": [
    "## b)to demonstrate Bag of words,TF & IDF Vectrization, N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82b30997-7ccb-4d77-9a9d-644b00dc6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Imports ----\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4aa227b4-8875-49dd-a2b8-edd9e4abbb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download tokenizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60b725c4-22be-4530-80b5-74c76f97ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion in 2025.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb57853b-2d27-49b5-8b47-768d441b2d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Apple', 'is', 'looking', 'at', 'buying', 'U.K.', 'startup', 'for', '$', '1', 'billion', 'in', '2025', '.']\n"
     ]
    }
   ],
   "source": [
    "# ---- 1. Tokenization ----\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1fb1109-1c8e-43e7-8c1d-26a6329e45c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BoW Words: ['2025' 'apple' 'at' 'billion' 'buying' 'for' 'in' 'is' 'looking'\n",
      " 'startup']\n",
      "BoW Counts: [[1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# ---- 2. Bag of Words (BoW) ----\n",
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform([text])\n",
    "print(\"\\nBoW Words:\", vectorizer.get_feature_names_out())\n",
    "print(\"BoW Counts:\", bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3dcf7819-2b57-44d5-8f2e-20b83b9ddecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Words: ['2025' 'apple' 'at' 'billion' 'buying' 'for' 'in' 'is' 'looking'\n",
      " 'startup']\n",
      "TF-IDF Values: [[0.31622777 0.31622777 0.31622777 0.31622777 0.31622777 0.31622777\n",
      "  0.31622777 0.31622777 0.31622777 0.31622777]]\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. TF-IDF ----\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform([text])\n",
    "print(\"\\nTF-IDF Words:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF Values:\", tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4368ff40-cd2f-47d1-8377-a5a926b47edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams: [('Apple', 'looking'), ('looking', 'buying'), ('buying', 'startup'), ('startup', 'billion')]\n",
      "Trigrams: [('Apple', 'looking', 'buying'), ('looking', 'buying', 'startup'), ('buying', 'startup', 'billion')]\n"
     ]
    }
   ],
   "source": [
    "#N-grams → Generating word pairs/triples\n",
    "# N-grams\n",
    "print(\"Bigrams:\", list(ngrams(filtered, 2)))\n",
    "print(\"Trigrams:\", list(ngrams(filtered, 3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
