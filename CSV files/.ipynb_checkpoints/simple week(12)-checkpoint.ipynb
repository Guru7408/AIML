{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39841843-7f55-4da8-9cdb-711adeff81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b52baf-7ac2-45c1-9338-d1061275a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4bba49-0599-46c8-ae4c-d66e0236cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple is looking at buying U.K. startup for $1 billion in 2025.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68ea6e3-c51e-4bc3-9213-5a05cb7651d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Apple', 'is', 'looking', 'at', 'buying', 'U.K.', 'startup', 'for', '$', '1', 'billion', 'in', '2025', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3f0909a-8b9c-4b8f-bf73-704602aac1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stopword Removal: ['Apple', 'looking', 'buying', 'startup', 'billion']\n"
     ]
    }
   ],
   "source": [
    "# Stopword Removal\n",
    "filtered = [w for w in tokens if w.isalpha() and w.lower() not in stopwords.words(\"english\")]\n",
    "print(\"After Stopword Removal:\", filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7475ec5-7b57-4bb8-9ff8-706318cd53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import string\n",
    "# Remove punctuation (just in case any remain)\n",
    "#punct = [w for w in filtered if w not in string.punctuation]\n",
    "\n",
    "#print(\"After Punctuation Removal:\",punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e158f4ef-cab5-447d-9f07-56dffa2a2207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('Apple', 'NNP'), ('looking', 'VBG'), ('buying', 'VBG'), ('startup', 'NN'), ('billion', 'CD')]\n"
     ]
    }
   ],
   "source": [
    "# POS Tagging\n",
    "print(\"POS Tags:\", pos_tag(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc704aef-64eb-44da-9a54-ef960b732511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER: [('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY'), ('2025', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "doc = nlp(text)\n",
    "print(\"NER:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514e2103-b7a1-4213-bb64-4c00ae4d18f8",
   "metadata": {},
   "source": [
    "## to demonstrate Bag of words,TF & IDF Vectrization, N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d4e5fb-835e-4f1a-8e25-78fa8d01c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb85f50-84a2-4f92-8954-ffaaaea7ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71e1ddc-852b-45ef-b55e-5cd5147a9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple is looking at buying U.K. startup for $1 billion in 2025.\"\n",
    "t2=\"buying new startup hi\"\n",
    "t3 = [ \"Apple is looking at buying U.K. startup for $1 billion in 2025.\",\n",
    "       \"buying new startup\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d2ac1b-b1a5-49f5-b433-4fc2366360dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Apple', 'is', 'looking', 'at', 'buying', 'U.K.', 'startup', 'for', '$', '1', 'billion', 'in', '2025', '.']\n"
     ]
    }
   ],
   "source": [
    "# ---- 1. Tokenization ----\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1057c523-711b-437d-a915-ca25e552c25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BoW Words: ['2025' 'apple' 'at' 'billion' 'buying' 'for' 'in' 'is' 'looking' 'new'\n",
      " 'startup']\n",
      "BoW Counts: [[1 1 1 1 1 1 1 1 1 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# ---- 2. Bag of Words (BoW) ----\n",
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(t3)\n",
    "print(\"\\nBoW Words:\", vectorizer.get_feature_names_out())\n",
    "print(\"BoW Counts:\", bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46044d9b-0d55-4bdf-8474-2c479afdaeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Words: ['2025' 'apple' 'at' 'billion' 'buying' 'for' 'hi' 'in' 'is' 'looking'\n",
      " 'new' 'startup']\n",
      "TF-IDF Values: [[0.33310232 0.33310232 0.33310232 0.33310232 0.23700504 0.33310232\n",
      "  0.         0.33310232 0.33310232 0.33310232 0.         0.23700504]\n",
      " [0.         0.         0.         0.         0.40993715 0.\n",
      "  0.57615236 0.         0.         0.         0.57615236 0.40993715]]\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. TF-IDF ----\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform([text,t2])\n",
    "print(\"\\nTF-IDF Words:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF Values:\", tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01cfb0b9-1b2e-4332-98f0-d183ff0bc26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Words: ['2025' 'apple' 'at' 'billion' 'buying' 'for' 'in' 'is' 'looking' 'new'\n",
      " 'startup']\n",
      "TF-IDF Values: [[0.33310232 0.33310232 0.33310232 0.33310232 0.23700504 0.33310232\n",
      "  0.33310232 0.33310232 0.33310232 0.         0.23700504]\n",
      " [0.         0.         0.         0.         0.50154891 0.\n",
      "  0.         0.         0.         0.70490949 0.50154891]]\n"
     ]
    }
   ],
   "source": [
    "# ---- 3. TF-IDF ----\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(t3)\n",
    "print(\"\\nTF-IDF Words:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF Values:\", tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "193c1a32-6240-4257-a706-c104642fe741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams: [('Apple', 'is'), ('is', 'looking'), ('looking', 'at'), ('at', 'buying'), ('buying', 'U.K.'), ('U.K.', 'startup'), ('startup', 'for'), ('for', '$'), ('$', '1'), ('1', 'billion'), ('billion', 'in'), ('in', '2025'), ('2025', '.')]\n",
      "Trigrams: [('Apple', 'is', 'looking'), ('is', 'looking', 'at'), ('looking', 'at', 'buying'), ('at', 'buying', 'U.K.'), ('buying', 'U.K.', 'startup'), ('U.K.', 'startup', 'for'), ('startup', 'for', '$'), ('for', '$', '1'), ('$', '1', 'billion'), ('1', 'billion', 'in'), ('billion', 'in', '2025'), ('in', '2025', '.')]\n"
     ]
    }
   ],
   "source": [
    "# N-grams\n",
    "print(\"Bigrams:\", list(ngrams(tokens, 2)))\n",
    "print(\"Trigrams:\", list(ngrams(tokens, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a709b-2c2a-466f-a91b-3d188393f554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
